{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa39d8d5-9559-47db-9eb5-48aa1752384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lr(model, train_loader, optimizer, criterion, init_value=1e-8, final_value=10.0, beta=0.98):\n",
    "    num = len(train_loader) - 1\n",
    "    mult = (final_value / init_value) ** (1/num)\n",
    "    lr = init_value\n",
    "    optimizer.param_groups[0]['lr'] = lr\n",
    "    avg_loss = 0.0\n",
    "    best_loss = 0.0\n",
    "    losses = []\n",
    "    log_lrs = []\n",
    "\n",
    "    #    for batch_idx, (before, target, future, after, m_b, b_t, m_a, timestamps) in enumerate(train_dataloader):        \n",
    "\n",
    "    for batch_num, (before, target, future, after, m_b, b_t, m_a, timestamps) in enumerate(train_loader, 1):\n",
    "        #inputs, targets = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(before, after, future)\n",
    "        loss = criterion(outputs, target)\n",
    "        avg_loss = beta * avg_loss + (1 - beta) * loss.data.item()\n",
    "        smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
    "        if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
    "            break\n",
    "        if smoothed_loss < best_loss or batch_num == 1:\n",
    "            best_loss = smoothed_loss\n",
    "        losses.append(smoothed_loss)\n",
    "        #log_lrs.append(math.log10(lr))\n",
    "        log_lrs.append(np.log10(lr))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        lr *= mult\n",
    "        optimizer.param_groups[0]['lr'] = lr\n",
    "\n",
    "    plt.plot(log_lrs[10:-5], losses[10:-5])\n",
    "    plt.xlabel('Log Learning Rate')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1734ee71-118d-479f-815d-0256c2ab6631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: cercare pytorch lighning\n",
    "train_dataset = CustomDataset(train_df, BATCH_SIZE)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=True, drop_last=True)\n",
    "loss = nn.L1Loss()\n",
    "model = NeuralNetwork()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "find_lr(model, train_dataloader, optimizer, loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
